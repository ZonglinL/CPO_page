<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="NeurIPS2025">
  <meta property="og:title" content="Diffusoin"/>
  <meta property="og:description" content="Diffusion"/>
  <!--<meta property="og:url" content="https://zonglinl.github.io/CPO_page/"/>-->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style>
      .item img {
          display: block;
          margin-left: auto;
          margin-right: auto;
          margin-up: auto;
          margin-down: auto;
      }
  </style>
  <title>CPO: Condition Preference Optimization for Controllable Image Generation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <!--<link rel="stylesheet" href="static/css/fontawesome.all.min.css">-->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <!--<script defer src="static/js/fontawesome.all.min.js"></script>-->
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">CPO: Condition Preference Optimization for Controllable Image Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://zonglinl.github.io/" target="_blank">Zonglin Lyu</a>,</span>
                <span class="author-block">
                <a href="https://liming-ai.github.io/" target="_blank">Ming Li</a>,</span>
                <span class="author-block">
                <a href="https://openreview.net/profile?id=~Xinxin_Liu4" target="_blank">Xnxin Liu</a>,</span>
                  <span class="author-block">
                    <a href="https://www.crcv.ucf.edu/chenchen/" target="_blank">Chen Chen</a>
                  </span>
          
                <span class="author-block">
                  </div>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institute of Artificial Intelligence, University of Central Florida<br> <b>NeurIPS 2025</b></span>
                  </div>
                  
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="TODO" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                      </>
                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ZonglinL/CPO" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>


                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="TODO" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <iframe height="480" width="960" 
            src="TODO"> 
      </iframe> 
    </div>
  </div>
</section>
<!-- End teaser video -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>To enhance controllability in text-to-image generation, ControlNet introduces image-based control signals, while ControlNet++ improves pixel-level cycle consistency between generated images and the input control signal. To avoid the prohibitive cost of back-propagating through the sampling process, ControlNet++ optimizes only low-noise timesteps (e.g., t < 200) using a single-step approximation, which not only ignores the contribution of high-noise timesteps but also introduces additional approximation errors. A straightforward alternative for optimizing controllability across all timesteps is Direct Preference Optimization (DPO), a fine-tuning method that increases model preference for more controllable images (I<sup>w</sup>}) over less controllable ones (I^<sup>l</sup>). However, due to uncertainty in generative models, it is difficult to ensure that win--lose image pairs differ only in controllability while keeping other factors, such as image quality, fixed. To address this, we propose performing preference learning over control conditions rather than generated images. Specifically, we construct winning and losing control signals, <b>c<sup>w</sup></b> and <b>c<sup>l</sup></b> , and train the model to prefer  <b>c<sup>w</sup></b>. This method, which we term \textit{Condition Preference Optimization} (CPO), eliminates confounding factors and yields a low-variance training objective. Our approach theoretically exhibits lower contrastive loss variance than DPO and empirically achieves superior results. Moreover, CPO requires less computation and storage for dataset curation. Extensive experiments show that CPO significantly improves controllability over the state-of-the-art ControlNet++ across multiple control types: over 10% error rate reduction in segmentation, 70 -- 80% in human pose, and consistent 2%--5% reductions in edge and depth maps. Here, the error rate is defined as the difference between the evaluated controllability and the oracle results.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Overview image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
              Recent method such as ControlNet++ improves the controllability of ConrolNet, but its training is not applicable to all diffusion timesteps. Diffusion DPO is a nature solution that can be applied to all timesteps to improve controllability by prefer I<sup>w</sup> (better controllability) over I<sup>l</sup> (weaker controllability), but some types of conditions such as edges are hard o observe in raw images which prevent model from learning a clear preference signal. Moreover, it is also challenging to ensure other factors such as quality of I<sup>w</sup> is better than or the same as I<sup>l</sup>, which injects noise for preference signal. Therefore, we propose CPO: Condition Preference Optimization to improve the controllability of image generation model. Instead of Contrasting images, our proposed method contrast conditions directly. As a result, the model sees a clear contrasting signal from the conditions and learns to improve the controllabiliy.
          </p>
        </div>
      </div>
    </div>
    <div class="hero-body">
    <img src="static/images/overview.png" alt="overview"/>
      </img>
      <h4 class="subtitle has-text-centered">
        (a) DPO learns to prefer I<sup>w</sup> over I<sup>l</sup>. (b) CPO learns to prefer <b>c<sup>w</sup></b> over <b>c<sup>l</sup></b>.
      </h4>
    </div>
  </div>
</section>
<!-- End overview image -->



<!-- Teaser-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Key Difference with DPO</h2>
        <div class="content has-text-justified">
          <p>
            To construct DPO dataset, we need to generate a group (we set it as 20) and find the best controllable (I<sup>w</sup>) and worst controllable ones (I<sup>l</sup>). Then we use ImageReward score to make sure the reward score of I<sup>w</sup> is obviously better. However, we only need to generate one sample I and detect the conditions from I as <b>c<sup>l</sup></b>. The ground truth condition (or the condition detects from the ground truth image) serves as <b>c<sup>w</sup></b>. Importantly, in DPO, the conditions may not be easy to observe from the image, making it hard for the model to learn the preference.
          </p>
        </div>
      </div>
    </div>
    <div class="hero-body">
    <img src="static/images/Teaser.png" alt="arch"/>
      </img>
      <h4 class="subtitle has-text-centered"> (a) dataset generation process of DPO. (b) dataset generation process of CPO. (c) Even with ImageReward filtering, DPO dataset still cannot ensure I<sup>w</sup> achieves bettter quality (Pose example, artifact in red circle) than I<sup>l</sup>, resulting in noisy preference. Moreover, conditions like edges are hardly observable in raw images (Canny example), which can confuse the model. CPO resolves this issue by directly contrasting conditions.
      </h4>
    </div>
  </div>
</section>
<!-- End Teaser -->
  

<!-- Quantitatve Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Quantitative Results</h2>
        <div class="content has-text-justified">
          <p>
            Our methods achieve the state-of-the-art results in Controllability without impact on image quality and text-to-image alignment. Recent work (ControlAR) reveals that DINO-v2 can improve the controllability and generation quality in controllable generation task. This observation also exists in Diffusion-based method.
          </p>
        </div>
      </div>
    </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/Controllability.png" alt="Controllability"/>
        <h4 class="subtitle has-text-centered">
          Quantitative Comparisons with recent SOTAs on Controllability. &uarr means the higher the better, and &darr means the lower the better. Since ControlAR uses CFG scale of 4 while diffusion-based methods use 7.5, we evaluate our method under CFG scale 4 to compare with ControlAR and CFG scale 7.5 to compare with other methods. Under the same setup, our method achieves the state-of-the-art results in Controllability. Click the "next" icon to see the quantitative comparison on FID/CLIP between our method and recent SOTAs.
        </h4>
        </div>

       <div class="item">
        <!-- Your image here -->
        <img src="static/images/FID.png" alt="FID"/>
        <h4 class="subtitle has-text-centered">
          Quantitative Comparisons with recent SOTAs on FID/CLIP. &uarr means the higher the better, and &darr means the lower the better. Click the "next" icon to see the ablation study of DINO-v2 adapter on Controllability.
        </h4>
      </div>

        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/DINO-Controllability.png" alt="DINO-C"/>
        <h4 class="subtitle has-text-centered">
         DINO-v2 adapter generally improves the controllability. &uarr means the higher the better, and &darr means the lower the better. Click the "next" icon to see the ablation study of DINO-v2 adapter on FID/CLIP.
        </h4>
      </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/DINO-FID.png" width="90%" alt="DINO-F"/>
        <h4 class="subtitle has-text-centered">
         DINO-v2 adapter generally improves the FID and CLIP score. &uarr means the higher the better, and &darr means the lower the better.
        </h4>
  </div>
</div>
</div>
</section>
<!-- End Quantitative Results -->
  
<!-- Qualitative Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Qualitative Results</h2>
        <div class="content has-text-justified">
          <p>
          </p>
        </div>
      </div>
    </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/Qual1.png" alt="Qual1"/>
        <h4 class="subtitle has-text-centered">
         Qualitative Comparisons with recent SOTAs. Click the "next" icon to see the qualitative comparisons on pose and lineart tasks.
        </h4>
        </div>

       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Pose_Line.png" alt="PL"/>
        <h4 class="subtitle has-text-centered">
          Qualitative Comparisons with recent SOTAs. Click the "next" icon to see additional qualitative comparisons.
        </h4>
      </div>

        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Qual2.png" alt="Qual2"/>
        <h4 class="subtitle has-text-centered">
         Qualitative Comparisons with recent SOTAs. Click the "next" icon to see our visual examples.
        </h4>
      </div>
        
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Pose_vis.png" width="90%" alt="Pose"/>
        <h4 class="subtitle has-text-centered">
         Visual Examples in Human Pose task. Click the "next" icon to see our visual examples.
        </h4>
  </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Seg_vis.png" width="90%" alt="Seg"/>
        <h4 class="subtitle has-text-centered">
         Visual Examples in Segmentation task. Click the "next" icon to see our visual examples.
        </h4>
  </div>


      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Line_vis.png" width="90%" alt="Lineart"/>
        <h4 class="subtitle has-text-centered">
         Visual Examples in Lineart task. Click the "next" icon to see our visual examples.
        </h4>
  </div>

      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Hed_vis.png" width="90%" alt="Hed"/>
        <h4 class="subtitle has-text-centered">
         Visual Examples in Hed task. Click the "next" icon to see our visual examples.
        </h4>
  </div>

      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Canny_vis.png" width="90%" alt="Canny"/>
        <h4 class="subtitle has-text-centered">
         Visual Examples in Canny Edge task. Click the "next" icon to see our visual examples.
        </h4>
  </div>

      <div class="item">
        <!-- Your image here -->
        <img src="static/images/Depth_vis.png" width="90%" alt="Depth"/>
        <h4 class="subtitle has-text-centered">
         Visual Examples in Depth task. Click the "next" icon to see our visual examples.
        </h4>
  </div>
</div>
</div>
</section>
<!-- End Qualitative Results -->


  
<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

  </body>
  </html>
