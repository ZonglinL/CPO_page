<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="ICCV2025">
  <meta property="og:title" content="Video Interpolation"/>
  <meta property="og:description" content="Video Interpolation"/>
  <!--<meta property="og:url" content="https://zonglinl.github.io/tlbvfi_page.github.io/"/>-->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style>
      .item img {
          display: block;
          margin-left: auto;
          margin-right: auto;
          margin-up: auto;
          margin-down: auto;
      }
  </style>
  <title>TLB-VFI: Temporal-Aware Latent Brownian Bridge Diffusion for Video Frame Interpolation</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <!--<link rel="stylesheet" href="static/css/fontawesome.all.min.css">-->
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <!--<script defer src="static/js/fontawesome.all.min.js"></script>-->
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TLB-VFI: Temporal-Aware Latent Brownian Bridge Diffusion for Video Frame Interpolation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://zonglinl.github.io/" target="_blank">Zonglin Lyu</a>,</span>
                  <span class="author-block">
                    <a href="https://www.crcv.ucf.edu/chenchen/" target="_blank">Chen Chen</a>
                  </span>
          
                <span class="author-block">
                  </div>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Center for Research in Compter VisionUniversity of Central Florida<br> <b>ICCV 2025</b></span>
                  </div>
                  
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2405.05953" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                      </>
                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ZonglinL/TLBVFI" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>


                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2405.05953" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <iframe height="480" width="960" 
            src="https://www.youtube.com/embed/WUa6L_fmTlM"> 
      </iframe> 
    </div>
  </div>
</section>
<!-- End teaser video -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Video Frame Interpolation (VFI) aims to predict the intermediate frame I<sub>n</sub> (we use n to denote time in videos to avoid notation overload with the timestep t in diffusion models) based on two consecutive neighboring frames I<sub>0</sub> and I<sub>1</sub>. Recent approaches apply diffusion models (both image-based and video-based) in this task and achieve strong performance. However, image-based diffusion models are unable to extract temporal information and are relatively inefficient compared to non-diffusion methods. Video-based diffusion models can extract temporal information, but they are too large in terms of training scale, model size, and inference time. To mitigate the above issues, we propose Temporal-Aware Latent Brownian Bridge Diffusion for Video Frame Interpolation (TLB-VFI), an efficient video-based diffusion model. By extracting rich temporal information from video inputs through our proposed 3D-wavelet gating and temporal-aware autoencoder, our method achieves <b>20%</b> improvement in FID on the most challenging datasets over recent SOTA of image-based diffusion models. Meanwhile, due to the existence of rich temporal information, our method achieves strong performance while having 3x fewer parameters. Such a parameter reduction results in 2.3x speed up. By incorporating optical flow guidance, our method requires 9000x less training data and achieves over 20x fewer parameters than video-based diffusion models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Overview image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
              Image diffusion-based methods in Video Frame Interpolation (VFI) achieves strong performance but fails to incorporate temporal information. Video diffusion-based models are able to extract temporal information but requires significantly larger datasets. We incorporate temporal information extraction and optical flow guidance and propose our temporal-aware Brownian Bridge Diffusion to improve the temporal consistency of generated frames and reduce the computation costs.
          </p>
        </div>
      </div>
    </div>
    <div class="hero-body">
    <img src="static/images/overview.jpg" alt="overview"/>
      </img>
      <h2 class="subtitle has-text-centered">
        Overview of our method. (a) Training autoencoder. The autoencoder is trained with video clip V = [I<sub>0</sub>, I<sub>n</sub>, I<sub>1</sub>] and aims to reconstruct I<sub>n</sub>. It contains an image encoder (shared for all frames) and an image decoder, where multi-level encoder features from I<sub>0</sub>, I<sub>1</sub> are passed to the decoder. Temporal blocks extract temporal information in the latent space and aggregate video features into a single image feature for the image decoder, and 3D Wavelet extracts temporal information in the pixel space. (b) Training Denoising UNet. The video clip V is encoded to x<sub>0</sub> by Encoder E (spatial + temporal). Since I<sub>n</sub> is unknown, we replace it by 0 and obtain another video clip V&#x0303 = [I<sub>0</sub>, 0, I<sub>1</sub>], which is encoded to x<sub>T</sub>. With the Brownian Bridge Diffusion Process, x<sub>t</sub> is computed and sent to denoising UNet to predict x<sub>t</sub> − x<sub>0</sub>. (c) Inference. During inference, we encode V&#x0303 to x<sub>T</sub> and sample with the Brownian Bridge Sampling Process to get x̂<sub>0</sub>, which is decoded to the output frame Î<sub>n</sub>.
      </h2>
    </div>
  </div>
</section>
<!-- End overview image -->



<!-- Architecture image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Architecture of The Autoencoder</h2>
        <div class="content has-text-justified">
          <p>
            Our autoencoder takes advantage of temporal information and optical flow to guide reconstruction.
          </p>
        </div>
      </div>
    </div>
    <div class="hero-body">
    <img src="static/images/Arch.jpg" alt="arch"/>
      </img>
      <h2 class="subtitle has-text-centered">
      (a) Model Pipeline. The Image Encoder is shared across all frames, and temporal blocks extract temporal information in the latent space. (b) Multi-level Feature Sharing. The Image Encoder and Decoder consist of several levels of resolution due to downsampling/upsampling latent features. At the ith level of the encoder and the decoder, features from I0 and I1 in the encoder are warped and concatenated with the original copy (when the downsampling rate is larger than 8, warped features are excluded). The concatenated features are used as keys and values in cross attention where the decoder feature at the same level is the query. (c) Encoder/Decoder Temporal Block. Each temporal block consists of two sets of 3D convolution + attention. In the decoder, the second attention is cross-attention between the intermediate frame (query) and all frames (key and value) to aggregate the video feature into one feature map. (d) 3D-wavelet Feature Gating. Wavelet information is extracted from the input video clip and encoded by CNNs. A sigmoid activation is applied, and the result is element-wise multiplied by the output of the Image Encoder with a skip connection.
      </h2>
    </div>
  </div>
</section>
<!-- End Architecture image -->
  

<!-- Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
          </p>
        </div>
      </div>
    </div>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/quant.png" alt="quantitative"/>
        <h2 class="subtitle has-text-centered">
          Quantitative Comparison between our method and recent SOTAs in LPIPS/FloLPIPS/FID (the lower the better). The best performance are <b>boldfaced</b>, and the second best performance are <u>underlined</u>.  Click the "next" icon to see the qualitative comparison between our method and recent SOTAs.
        </h2>
        </div>

       <div class="item">
        <!-- Your image here -->
        <img src="static/images/visual1.png" alt="sota"/>
        <h2 class="subtitle has-text-centered">
          Qualitative comparison between our method and recent SOTAs. Images cropped in <font color="blue"> blue boxes </font> are displayed for comparison, and <font color = "red">red circles</font> highlight our stronger performance. Click the "next" icon to see additional qualitative results.
        </h2>
      </div>

        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/visual2.png" alt="sota"/>
        <h2 class="subtitle has-text-centered">
          Additional Qualitative comparison between our method and recent SOTAs. Images cropped in <font color="blue"> blue boxes </font> are displayed for comparison, and <font color = "red">red circles</font> highlight our stronger performance. Click the "next" icon to see additional qualitative results.
        </h2>
      </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/visual3.png" width="90%" alt="ldm"/>
        <h2 class="subtitle has-text-centered">
         Additional Qualitative comparison between our method and recent SOTAs. Images cropped in <font color="blue"> blue boxes </font> are displayed for comparison, and <font color = "red">red circles</font> highlight our stronger performance.
        </h2>
  </div>
</div>
</div>
</section>
<!-- End Results -->
  
<!-- Multiframe -->

<!-- Image carousel -->
<section class="hero is-small">
    <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Multi-frame Interpolation</h2>
        <div class="content has-text-justified">
          <p>
          We interpolate 7 frames between two frames and visualize the generated video with <b>our method</b> and <b>PerVFI</b>. Click "next" icon to view more images.
          </p>
        </div>
      </div>
    </div>
    </div>
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_0_im_0.png" alt="vid0im1"/>
        <h2 class="subtitle has-text-centered">
          The starting frame of multiframe interpolation. Click the "next" icon to see the ending frame.
        </h2>
        </div>

        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_0_im_1.png" alt="vid0im1"/>
        <h2 class="subtitle has-text-centered">
          The ending frame of multiframe interpolation. Click the "next" icon to see our interpolation result.
        </h2>
        </div>
        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/our0.gif" alt="our0"/>
        <h2 class="subtitle has-text-centered">
          Multiframe interpolation result of <b>our method</b>. The first and the last frame are given, the middle 7 frames are interpolated. Click the "next" icon to see the result of PerVFI
        </h2>
      </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/per0.gif" alt="per0"/>
        <h2 class="subtitle has-text-centered">
          Multi-frame interpolation result of <b>PerVFI</b>. The first and the last frame are given, the middle 7 frames are interpolated. The tires are distorted.
        </h2>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->
  

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_1_im_0.png" alt="vid2im1"/>
        <h2 class="subtitle has-text-centered">
          The starting frame of multiframe interpolation. Click the "next" icon to see the ending frame.
        </h2>
        </div>

        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_1_im_1.png" alt="vid2im1"/>
        <h2 class="subtitle has-text-centered">
          The ending frame of multiframe interpolation. Click the "next" icon to see our interpolation result.
        </h2>
        </div>
        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/our1.gif" alt="our2"/>
        <h2 class="subtitle has-text-centered">
          Multiframe interpolation result of <b>our method</b>. The first and the last frame are given, the middle 7 frames are interpolated. Click the "next" icon to see the result of PerVFI
        </h2>
      </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/per1.gif" alt="ldm2"/>
        <h2 class="subtitle has-text-centered">
          Multi-frame interpolation result of <b>PerVFI</b>. The first and the last frame are given, the middle 7 frames are interpolated. The wings are distorted.
        </h2>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_2_im_0.png" alt="vid3im0"/>
        <h2 class="subtitle has-text-centered">
          The starting frame of multiframe interpolation. Click the "next" icon to see the ending frame.
        </h2>
        </div>

        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_2_im_1.png" alt="vid2im1"/>
        <h2 class="subtitle has-text-centered">
          The ending frame of multiframe interpolation. Click the "next" icon to see our interpolation result.
        </h2>
        </div>
        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/our2.gif" alt="our3"/>
        <h2 class="subtitle has-text-centered">
          Multiframe interpolation result of <b>our method</b>. The first and the last frame are given, the middle 7 frames are interpolated. Click the "next" icon to see the result of PerVFI
        </h2>
      </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/per2.gif" alt="ldm3"/>
        <h2 class="subtitle has-text-centered">
          Multi-frame interpolation result of <b>PerVFI</b>. The first and the last frame are given, the middle 7 frames are interpolated. The hand is distorted.
        </h2>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

  
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_3_im_0.png" alt="vid1im1"/>
        <h2 class="subtitle has-text-centered">
          The starting frame of multiframe interpolation. Click the "next" icon to see the ending frame.
        </h2>
        </div>

        <div class="item">
        <!-- Your image here -->
        <img src="static/images/vid_3_im_1.png" alt="vid0im1"/>
        <h2 class="subtitle has-text-centered">
          The ending frame of multiframe interpolation. Click the "next" icon to see our interpolation result.
        </h2>
        </div>
        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/our3.gif" alt="our1"/>
        <h2 class="subtitle has-text-centered">
          Multiframe interpolation result of <b>our method</b>. The first and the last frame are given, the middle 7 frames are interpolated. Click the "next" icon to see the result of PerVFI
        </h2>
      </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/per3.gif" alt="ldm1"/>
        <h2 class="subtitle has-text-centered">
          Multi-frame interpolation result of <b>PerVFI</b>. The first and the last frame are given, the middle 7 frames are interpolated. The eye is distorted.
        </h2>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<h1 class="subtitle has-text-centered">
<b>More Multiframe Interpolation Visualization of our method.</b> We interpolate 7 frames between two frames.
</h1>

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item" >
        <!-- Your image here -->
        <img src="static/images/our4.gif" alt="our4" />
        <h2 class="subtitle has-text-centered">
          Click the "next" icon to see more.
        </h2>
        </div>

        <div class="item">
        <!-- Your image here -->
        <img src="static/images/our5.gif" alt="our5" class="center"/>
        <h2 class="subtitle has-text-centered">
          Click the "next" icon to see more.
        </h2>
        </div>
        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/our6.gif" alt="our6" class="center"/>
        <h2 class="subtitle has-text-centered">
          Click the "next" icon to see more.
        </h2>
      </div>
          
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/our7.gif" alt="our7" class="center"/>
        <h2 class="subtitle has-text-centered">
         Click the "next" icon to see more.
        </h2>
      </div>


        <div class="item" >
        <!-- Your image here -->
        <img src="static/images/new0.gif" alt="new0" />
        <h2 class="subtitle has-text-centered">
          Click the "next" icon to see more.
        </h2>
        </div>

        <div class="item">
        <!-- Your image here -->
        <img src="static/images/new1.gif" alt="new1" class="center"/>
        <h2 class="subtitle has-text-centered">
          Click the "next" icon to see more.
        </h2>
        </div>
        
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/new2.gif" alt="new2" class="center"/>
        <h2 class="subtitle has-text-centered">
          Click the "next" icon to see more.
        </h2>
      </div>
          
</div>
</div>
</section>



  
<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
